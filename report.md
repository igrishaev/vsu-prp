Данный отчет помогает оценить

Программы запускались на ноутбуке MacBook Pro с процессором 2.6 GHz
Intel Core i5 (4 логических ядра). Использовался компилятор GCC версии
4.9. Технология ОМП достуна в этом компиляторе начиная с версии 4.4.

Программа создает две матрицы, заполняет случайными числами и
перемножает методом Фокса. Метод Фокса предполагает, что исходные
матрицы разбиваются на блоки. Таким образом, матрицу высшего уровня
можно считать матрицей, элементами которой... Результирующую матрицу
можно получить, выполнив умножение новых матриц стандартным
аглоритмом, с тем условием, что элементы будут матрицы-блоки, для
которых операции умножения и сложения справедливы как для обычных
матриц. Таким образом, алгоритм Фокса рекурсивен по своей природе и
хорошо разделяется на подзадачи.

Прежде всего, проверим корректность алгоритма на небольших
значениях. Исправим переменные `MTRX_SIZE` и `BLCK_SIZE` на 9 и 3
соответсвенно. Раскомментируем в коде программы секцию за вывод
результатов. Скомпилируем программу без поддержки ОПМ Команда

Запуск программы выведет следующее

```
   2   4   3   3   0   2   4   3   3
   4   0   0   2   2   2   3   2   4
   0   2   3   4   4   2   0   3   4
   3   1   0   2   1   2   2   0   3
   4   4   4   1   2   2   3   1   0
   0   3   1   4   2   1   3   3   4
   3   0   4   1   0   3   2   1   4
   4   1   3   2   3   3   3   3   1
   0   3   0   4   3   1   0   4   0

   4   4   1   2   0   0   4   1   3
   3   3   0   2   2   1   1   2   3
   4   1   2   1   3   2   3   2   2
   4   4   4   1   0   0   0   3   2
   4   3   2   0   2   4   3   0   3
   3   0   1   2   2   0   2   2   2
   1   0   2   1   1   0   1   3   2
   1   0   0   4   0   1   2   3   0
   4   4   3   4   0   0   1   3   1

  69  47  39  50  25  13  38  59  45
  59  46  36  41  11  10  37  41  36
  75  53  44  43  25  27  37  47  40
  47  38  28  28  10   5  25  30  30
  66  42  28  32  31  21  47  39  50
  62  48  41  44  18  16  27  52  37
  60  36  34  39  20   9  38  41  33
  70  43  36  40  26  22  51  45  47
  44  34  23  28  14  19  22  32  28
```

Выборочно проверив несколько элементов, убеждаемся, что алгоритм
работает корректно.

Теперь можно тестировать производительность программы. Для этого
закомментируем вывод данных и назначим объявлениям `MTRX_SIZE` и
`BLCK_SIZE` значения 1000 и 100. Итого исходные матрицы будут
состояить из миллиона целых чисел, размера блока составит 10 тысяч
элементов.

Скомпилируем программу без флага ОМП. Замерим запуск программы
стандартной UNIX-командой time:

```
gcc-4.9 matrix_fox.c -o matrix_fox
time ./matrix_fox
./matrix_fox  5.65s user 0.01s system 99% cpu 5.666 total
./matrix_fox  5.66s user 0.01s system 99% cpu 5.674 total
./matrix_fox  5.68s user 0.01s system 99% cpu 5.694 total
```

Среднее время исполнение составляет 5.66 секунд. При этом параметр cpu
не превышает отметки 100%. Это значит, что программа использует
только одно ядро. Использование технологии ОМП должно сократить время
исполнения и задействовать дополнительные ядра проессора.

Добавим поддержку ОМП в программу. Добавим в функцию matrix_mul,
непосредственно перед первым циклом for директиву компилятора

```
/* #pragma omp parallel for */
```

Скомпилируем программу, передав на этот раз флаг -fopenmp. Запустим
бинарный файл несколько раз

```
gcc-4.9 matrix_fox.c -o matrix_fox -fopenmp
time ./matrix_fox
./matrix_fox  6.34s user 0.01s system 259% cpu 2.444 total
./matrix_fox  6.45s user 0.02s system 310% cpu 2.081 total
./matrix_fox  5.82s user 0.01s system 207% cpu 2.815 total
./matrix_fox  6.91s user 0.01s system 297% cpu 2.325 total
./matrix_fox  6.07s user 0.01s system 283% cpu 2.150 total
./matrix_fox  6.60s user 0.01s system 280% cpu 2.359 total
./matrix_fox  6.99s user 0.01s system 338% cpu 2.072 total
./matrix_fox  5.98s user 0.01s system 218% cpu 2.743 total
./matrix_fox  5.90s user 0.01s system 254% cpu 2.326 total
./matrix_fox  6.17s user 0.02s system 288% cpu 2.144 total
./matrix_fox  6.04s user 0.02s system 245% cpu 2.464 total
./matrix_fox  7.08s user 0.02s system 347% cpu 2.042 total
```

Видим, что производительность программы выросла в два раза, при этом
зайдествованы несколько ядер, вплось до четырех в случае 347% cpu.

Попробуем распараллелить вложенный цикл. Закомментируем директиву омп
над внешним циклом и подставим аналогичную перед вторым оператором
for. Скомпилируем и замерим показатели

```
 make openmp
gcc-4.9 matrix_fox.c -o matrix_fox -fopenmp
time ./matrix_fox
./matrix_fox  6.43s user 0.01s system 288% cpu 2.235 total
./matrix_fox  6.85s user 0.01s system 300% cpu 2.281 total
./matrix_fox  6.79s user 0.01s system 312% cpu 2.174 total
./matrix_fox  6.32s user 0.01s system 289% cpu 2.188 total
./matrix_fox  6.79s user 0.01s system 284% cpu 2.386 total
./matrix_fox  6.74s user 0.01s system 291% cpu 2.317 total
./matrix_fox  6.72s user 0.01s system 301% cpu 2.230 total
./matrix_fox  6.58s user 0.01s system 311% cpu 2.117 total
./matrix_fox  6.45s user 0.01s system 296% cpu 2.181 total
./matrix_fox  6.41s user 0.01s system 271% cpu 2.359 total
./matrix_fox  7.08s user 0.01s system 309% cpu 2.291 total
./matrix_fox  6.27s user 0.01s system 295% cpu 2.124 total
```

Эта версия программы показывает аналогичные результаты. Среднее время
исполнения отличается ненамного, задействовано от трех до четырех ядер
процессора.

Опция collapse позволяет распараллелить сразу несколько вложенных
циклов. Так, чтобы не указывать для каждого оператора for директиву,
сделаем это на первом уровне, передав опцию collapse с параметром 2. В
строке 98 раскомментируем выражение.

```
#pragma omp parallel for collapse(2)

```

Замеры

```
gcc-4.9 matrix_fox.c -o matrix_fox -fopenmp
time ./matrix_fox
./matrix_fox  9.45s user 0.01s system 348% cpu 2.718 total
./matrix_fox  10.12s user 0.02s system 323% cpu 3.139 total
./matrix_fox  9.49s user 0.02s system 302% cpu 3.140 total
./matrix_fox  9.93s user 0.01s system 363% cpu 2.733 total
./matrix_fox  8.43s user 0.01s system 266% cpu 3.169 total
./matrix_fox  9.33s user 0.01s system 347% cpu 2.683 total
./matrix_fox  9.51s user 0.01s system 305% cpu 3.115 total
./matrix_fox  9.48s user 0.01s system 310% cpu 3.053 total
./matrix_fox  9.10s user 0.01s system 284% cpu 3.204 total
./matrix_fox  8.51s user 0.01s system 283% cpu 3.004 total
./matrix_fox  10.02s user 0.01s system 388% cpu 2.583 total
./matrix_fox  9.18s user 0.01s system 311% cpu 2.946 total
./matrix_fox  9.47s user 0.01s system 306% cpu 3.088 total
./matrix_fox  9.11s user 0.01s system 324% cpu 2.812 total
./matrix_fox  9.70s user 0.01s system 355% cpu 2.731 total
```

Новые показатели позволяют сделать следующий выводы. Во-первых, время
выполнения программы увеличилось в среднем на 0.9 секунды. Вместе с
тем, возрасла нагружка на процессор: величины cpu свыще 300%
встречаются чаще чем в случае перывх двух замеров. Исходя из этого,
логично предположить, что программа тратит больше ресурсов на
порождение новых тредов, что сказывается и на нагрузце ЦП.

В примерах выше испоьлзовали директивы без опции schedule. Эта опция
правляет распределением работы между нитями в конструкции
распределения работы цикла. Добавим ее с одним из возможных параметров
static, dynamic, guided, auto. Составим сводную таблицу с возможными
вариантами директив

static – блочно-циклическое распределение итераций цикла; размер блока – chunk. Первый блок из chunk итераций выполняет нулевая нить, второй блок – следующая и т.д. до последней нити, затем распределение снова начинается с нулевой нити. Если значение chunk не указано, то всё множество итераций делится на непрерывные куски примерно одинакового размера (конкретный способ зависит от реализации), и полученные порции итераций распределяются между нитями.
dynamic – динамическое распределение итераций с фиксированным размером блока: сначала каждая нить получает chunk итераций (по умолчанию chunk=1), та нить, которая заканчивает выполнение своей порции итераций, получает первую свободную порцию из chunk итераций. Освободившиеся нити получают новые порции итераций до тех пор, пока все порции не будут исчерпаны. Последняя порция может содержать меньше итераций, чем все остальные.
guided – динамическое распределение итераций, при котором размер порции уменьшается с некоторого начального значения до величины chunk (по умолчанию chunk=1) пропорционально количеству ещё не распределённых итераций, делённому на количество нитей, выполняющих цикл. Размер первоначально выделяемого блока зависит от реализации. В ряде случаев такое распределение позволяет аккуратнее разделить работу и сбалансировать загрузку нитей. Количество итераций в последней порции может оказаться меньше значения chunk.
auto – способ распределения итераций выбирается компилятором и/или системой выполнения. Параметр chunk при этом не задаётся.
runtime –

Позиция директивы | Параметр schedule | Avg t, sec | Avg CPU, %
------------------|-------------------|------------|-----------
-- | -- | 5.674 | 99
внешний for | static | 2.352 | 258
внешний for | dynamic | 1.991 | 387
внешний for | guided | 2.133 | 340
внешний for | auto | 2.103 | 301
внутренний for | static | 2.313 | 291
внутренний for | dynamic | 1.938 | 378
внутренний for | guided | 2.139 | 338
внутренний for | auto | 2.099 | 303
оба for | static | 2.830 | 352
оба for | dynamic |  2.632 | 391
оба for | guided | 2.722 | 361
оба for | auto | 2.731 | 367

На основании этих данных можно сделать несколько выводов.

- применение технологии ОМП однозначно повышает производительность
программы и позволяет зайдествовать аппаратные возможности платформы;
- применение параметра dynamic опции schedule дает в целом лучший
  результат с точки зрения производительности, но потребляет больше
  процессорной мощи;
- излишнее распараллеливание (два цикла вместо одного) может
отрицательно сказаться на производительность программы в целом.
